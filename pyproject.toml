[build-system]
requires = ["setuptools", "setuptools-scm"]
build-backend = "setuptools.build_meta"

[project]
name = "unsloth"
dynamic = ["version"]
description = "2-5X faster LLM finetuning"
readme = "README.md"
requires-python = ">=3.9"
license = {file = "LICENSE"}
keywords = ["ai", "llm",]
authors = [
    {email = "info@unsloth.ai"},
    {name = "Unsloth AI team"},
]
maintainers = [
    {name = "Daniel Han", email = "danielhanchen@gmail.com"},
    {name = "Michael Han", email = "info@unsloth.ai"},
]
classifiers = [
    "Programming Language :: Python",
]

[tool.setuptools.dynamic]
version = {attr = "unsloth.__version__"}

[tool.setuptools]
include-package-data = false

[tool.setuptools.packages.find]
exclude = ["images*"]

[project.optional-dependencies]
huggingface = [
    "transformers>=4.37.0",
    "datasets",
    "sentencepiece",
    "accelerate>=0.26.1",
    "trl>=0.7.9",
    "peft>=0.7.1",
    "tqdm",
    "psutil",
]
cu118only = [
    "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl ; python_version=='3.9'",
    "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl ; python_version=='3.10'",
    "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl ; python_version=='3.11'",
]
cu121only = [
    "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp39-cp39-manylinux2014_x86_64.whl ; python_version=='3.9'",
    "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl ; python_version=='3.10'",
    "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.22.post7-cp311-cp311-manylinux2014_x86_64.whl ; python_version=='3.11'",
]
cu118onlytorch211 = [
    "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23%2Bcu118-cp39-cp39-manylinux2014_x86_64.whl ; python_version=='3.9'",
    "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl ; python_version=='3.10'",
    "xformers @ https://download.pytorch.org/whl/cu118/xformers-0.0.23%2Bcu118-cp311-cp311-manylinux2014_x86_64.whl ; python_version=='3.11'",
]
cu121onlytorch211 = [
    "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp39-cp39-manylinux2014_x86_64.whl ; python_version=='3.9'",
    "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp310-cp310-manylinux2014_x86_64.whl ; python_version=='3.10'",
    "xformers @ https://download.pytorch.org/whl/cu121/xformers-0.0.23-cp311-cp311-manylinux2014_x86_64.whl ; python_version=='3.11'",
]
cu118 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu118only]",
]
cu121 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu121only]",
]
cu118_torch211 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu118onlytorch211]",
]
cu121_torch211 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu121onlytorch211]",
]
kaggle = [
    "unsloth[huggingface]",
]
conda = [
    "unsloth[huggingface]",
]
colab = [
    "unsloth[cu121]",
]
colab_ampere = [
    "unsloth[cu121]",
    "packaging",
    "ninja",
    "flash-attn",
]
colab_torch211 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu121onlytorch211]",
]
colab_ampere_torch211 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu121onlytorch211]",
    "packaging",
    "ninja",
    "flash-attn",
]
cu118_ampere = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu118only]",
    "packaging",
    "ninja",
    "flash-attn",
]
cu121_ampere = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu121only]",
    "packaging",
    "ninja",
    "flash-attn",
]
cu118_ampere_torch211 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu118onlytorch211]",
    "packaging",
    "ninja",
    "flash-attn",
]
cu121_ampere_torch211 = [
    "unsloth[huggingface]",
    "bitsandbytes",
    "unsloth[cu121onlytorch211]",
    "packaging",
    "ninja",
    "flash-attn",
]

[project.urls]
homepage = "http://www.unsloth.ai"
documentation = "https://github.com/unslothai/unsloth"
repository = "https://github.com/unslothai/unsloth"
